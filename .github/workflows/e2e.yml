# If you change this name also do it in ci_metrics.yml
name: end-to-end

on:
  workflow_dispatch: # Activate this workflow manually
  schedule:
    - cron: "0 0 * * *"
  pull_request:
    types:
      - opened
      - reopened
      - synchronize
      - ready_for_review
    paths:
      - "e2e/**/*.py"
      - "!e2e/preview/**/*.py"   # See e2e_preview.yml
      - ".github/workflows/e2e.yml"

env:
  PYTHON_VERSION: "3.8"
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  COHERE_API_KEY: ${{ secrets.COHERE_API_KEY }}
  SERPERDEV_API_KEY: ${{ secrets.SERPERDEV_API_KEY }}

jobs:
  e2e:
    timeout-minutes: 60
    strategy:
      fail-fast: false  # Avoid cancelling the others if one of these fails
      matrix:
        folder:
          - "document_search"
          - "pipelines"
          - "preview"

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt install ffmpeg  # for local Whisper tests

    - name: Run Elasticsearch
      run: |
        docker run -d -p 9200:9200 -e "discovery.type=single-node" -e "ES_JAVA_OPTS=-Xms128m -Xmx256m" elasticsearch:7.9.2

    - name: Run Opensearch
      run: |
        docker run -d -p 9201:9200 -p 9600:9600 -e "discovery.type=single-node" opensearchproject/opensearch:1.3.5

    - name: Run Weaviate
      run: docker run -d -p 8080:8080 --name haystack_test_weaviate --env AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED='true' --env PERSISTENCE_DATA_PATH='/var/lib/weaviate' --env ENABLE_EXPERIMENTAL_BM25='true' --env DISK_USE_READONLY_PERCENTAGE='95' semitechnologies/weaviate:1.17.2

    - name: Install Haystack
      run: pip install -e .[inference,elasticsearch7,faiss,weaviate,opensearch,dev,pdf,preview] langdetect

    # FIXME caching prevents PRs from running the e2e tests properly

    # - name: Cache HF models
    #   id: cache-hf-models
    #   uses: actions/cache@v3
    #   with:
    #     path: ./e2e
    #     key: ${{ runner.os }}-${{ hashFiles('**/models_to_cache.txt') }}
    #   env:
    #     SEGMENT_DOWNLOAD_TIMEOUT_MINS: 15

    # - name: Download models
    #   if: steps.cache-hf-models.outputs.cache-hit != 'true'
    #   shell: python
    #   run: |
    #     from transformers import AutoModel
    #     with open("./e2e/models_to_cache.txt") as file:
    #       AutoModel.from_pretrained(file.readline().rstrip())

    - name: Run tests
      env:
        TOKENIZERS_PARALLELISM: 'false'  # Avoid logspam by tokenizers
      # we add "and not document_store" to exclude the tests that were ported to the new strategy
      run: |
        pytest e2e/${{ matrix.folder }}
