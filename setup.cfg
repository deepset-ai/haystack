[metadata]
name = farm-haystack
version = file: VERSION.txt
url = https://github.com/deepset-ai/haystack
project_urls =
    Docs: RTD = https://haystack.deepset.ai/overview/intro
    CI: GitHub = https://github.com/deepset-ai/haystack/actions
    GitHub: issues = https://github.com/deepset-ai/haystack/issues
    GitHub: repo = https://github.com/deepset-ai/haystack
description = Neural Question Answering & Semantic Search at Scale. Use modern transformer based models like BERT to find answers in large document collections
long_description = file: README.md
long_description_content_type = text/markdown
keywords=
    QA 
    Question-Answering 
    Reader 
    Retriever 
    semantic-search 
    search 
    BERT 
    roberta 
    albert 
    squad 
    mrc 
    transfer-learning 
    language-model 
    transformer
author = deepset.ai
author_email = malte.pietsch@deepset.ai
license = Apache License 2.0
license_file = LICENSE
platforms = any
classifiers =
    Development Status :: 5 - Production/Stable
    Intended Audience :: Science/Research
    License :: Freely Distributable
    License :: OSI Approved :: Apache Software License
    Topic :: Scientific/Engineering :: Artificial Intelligence
    Operating System :: OS Independent
    Programming Language :: Python
    Programming Language :: Python :: 3
    Programming Language :: Python :: 3.7
    Programming Language :: Python :: 3.8
    Programming Language :: Python :: 3.9
    Programming Language :: Python :: 3.10

[options]
use_scm_version = True
python_requires = >=3.7, <4
packages = find:
setup_requires =
    setuptools
    wheel
install_requires =
    importlib-metadata; python_version < '3.8'
    torch>1.9,<1.11
    requests
    pydantic
    transformers==4.13.0
    nltk
    pandas

    # Utils
    dill  # pickle extension for (de-)serialization
    tqdm  # progress bars in model download and training scripts
    networkx  # graphs library
    mmh3  # fast hashing function (murmurhash3)
    quantulum3  # quantities extraction from text
    azure-ai-formrecognizer==3.2.0b2  # forms reader
    # azure-core is a dependency of azure-ai-formrecognizer
    # In order to stop malicious pip backtracking during pip install farm-haystack[all] documented in https://github.com/deepset-ai/haystack/issues/2280 
    # we have to resolve a dependency version conflict ourself.
    # azure-core>=1.23 conflicts with pydoc-markdown's dependency on databind>=1.5.0 which itself requires typing-extensions<4.0.0
    # azure-core>=1.23 needs typing-extensions>=4.0.1
    # pip unfortunately backtracks into the databind direction ultimately getting lost.
    azure-core<1.23

    # Preprocessing
    more_itertools  # for windowing
    python-docx
    langdetect   # for PDF conversions
    tika  # Apache Tika (text & metadata extractor)

    # See haystack/nodes/retriever/_embedding_encoder.py, _SentenceTransformersEmbeddingEncoder
    sentence-transformers>=0.4.0

    # for stats in run_classifier
    scipy>=1.3.2  
    scikit-learn>=1.0.0

    # Metrics and logging
    seqeval
    mlflow<=1.13.1 

    # Elasticsearch
    elasticsearch>=7.7,<=7.10
    elastic-apm

    # Schema validation
    jsonschema

    # Not found in repo, to review:
    #uvloop==0.14; sys_platform != 'win32' and sys_platform != 'cygwin'


[options.packages.find]
exclude =
    rest_api*
    test*
    tutorials*
    ui*
include = 
    json-schemas


[options.extras_require]
sql = 
    sqlalchemy>=1.4.2,<2
    sqlalchemy_utils
    psycopg2-binary; sys_platform != 'win32' and sys_platform != 'cygwin'
only-faiss = 
    faiss-cpu>=1.6.3,<2
faiss = 
    farm-haystack[sql,only-faiss]
only-faiss-gpu = 
    faiss-gpu>=1.6.3,<2
faiss-gpu = 
    farm-haystack[sql,only-faiss-gpu]
only-milvus1 = 
    pymilvus<2.0.0  # Refer milvus version support matrix at https://github.com/milvus-io/pymilvus#install-pymilvus
milvus1 = 
    farm-haystack[sql,only-milvus1]
only-milvus = 
    pymilvus>=2.0.0,<3  # Refer milvus version support matrix at https://github.com/milvus-io/pymilvus#install-pymilvus
milvus = 
    farm-haystack[sql,only-milvus]
weaviate =
    weaviate-client==2.5.0
graphdb = 
    SPARQLWrapper
docstores =
    farm-haystack[faiss,milvus,weaviate,graphdb]
docstores-gpu =
    farm-haystack[faiss-gpu,milvus,weaviate,graphdb]
crawler = 
    selenium
    webdriver-manager
preprocessing = 
    beautifulsoup4
    markdown
ocr = 
    pytesseract==0.3.7
    pillow
    pdf2image==1.14.0
onnx = 
    onnxruntime
    onnxruntime_tools
onnx-gpu = 
    onnxruntime-gpu
    onnxruntime_tools
ray = 
    ray>=1.9.1,<2
    aiorwlock>=1.3.0,<2
colab = 
    grpcio==1.43.0
dev = 
    # Type check
    mypy
    typing_extensions; python_version < '3.8'
    # Test
    pytest
    responses
    tox
    coverage
    python-multipart
    psutil
    # Linting
    pylint
    # Code formatting
    black[jupyter] 
    # Documentation
    pydoc-markdown==4.5.1   # FIXME Unpin!
    mkdocs 
    jupytercontrib 
    watchdog  #==1.0.2
test = 
    farm-haystack[docstores,crawler,preprocessing,ocr,ray,dev]
all =
    farm-haystack[docstores,crawler,preprocessing,ocr,ray,dev,onnx]
all-gpu =
    farm-haystack[docstores-gpu,crawler,preprocessing,ocr,ray,dev,onnx-gpu]


[tool:pytest]
testpaths = 
    test
    rest_api/test
    ui/test
python_files =
    test_*.py
addopts =
    -vv


[mypy]
warn_return_any = false
warn_unused_configs = true
ignore_missing_imports = true
plugins = pydantic.mypy


[tox]
requires = tox-venv
           setuptools >= 30.0.0
envlist = py36,py37


[testenv]
changedir = test
deps =
    coverage
    pytest
    pandas
setenv =
    COVERAGE_FILE = test-reports/.coverage
    PYTEST_ADDOPTS = --junitxml=test-reports/{envname}/junit.xml -vv
commands =
    coverage run --source haystack --parallel-mode -m pytest {posargs}
    coverage combine
    coverage report -m
    coverage html -d test-reports/coverage-html
    coverage xml -o test-reports/coverage.xml
