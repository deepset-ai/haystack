---
features:
  - |
    Pipelines now support list wrapping: a component returning type T can be connected to a component expecting type
    list[T]. The output will be wrapped automatically.

    In addition, Pipelines support automatic conversion between list[T] and T, for str and ChatMessage types only.
    When converting from list[T] to T, the first element of the list is used. If the list is empty, an
    informative ``PipelineRuntimeError`` is raised.

    With other recent changes, this makes pipelines more flexible and removes the need for explicit adapter components
    in many cases.
    For example, the following pipeline automatically converts a ``list[ChatMessage]`` produced by the LLM into a ``str``
    expected by the retriever, which previously required an Output Adapter component.

    .. code:: python
      from haystack.document_stores.in_memory import InMemoryDocumentStore
      from haystack.dataclasses import Document
      from haystack.components.retrievers import InMemoryBM25Retriever
      from haystack import Pipeline
      from haystack.components.builders import ChatPromptBuilder
      from haystack.components.generators.chat import OpenAIChatGenerator

      document_store = InMemoryDocumentStore()

      documents = [
          Document(content="Bob lives in Paris."),
          Document(content="Alice lives in London."),
          Document(content="Ivy lives in Melbourne."),
          Document(content="Kate lives in Brisbane."),
          Document(content="Liam lives in Adelaide."),
      ]

      document_store.write_documents(documents)

      template ="""{% message role="user" %}
      Rewrite the following query to be used for keyword search.
      {{ query }}
      {% endmessage %}
      """

      p = Pipeline()
      p.add_component("prompt_builder", ChatPromptBuilder(template=template))
      p.add_component("llm", OpenAIChatGenerator(model="gpt-4.1-mini"))
      p.add_component("retriever", InMemoryBM25Retriever(document_store=document_store, top_k=3))

      p.connect("prompt_builder", "llm")
      p.connect("llm", "retriever")

      query = """Someday I'd love to visit Brisbane, but for now I just want
      to know the names of the people who live there."""

      results = p.run(data={"prompt_builder": {"query": query}})
